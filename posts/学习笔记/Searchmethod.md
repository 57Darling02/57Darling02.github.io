---
title: Searchmethod (一)
date: 2024-09-23 21:12:48
copyright: true
tags: Learn 优化算法
---

# Searchmethod（一）

​	Record and summary the search methods.

​	References are from CSDN

### 无信息搜索方法（Blind Search Methods）

#### 1. **宽度优先搜索（Breadth-First Search, BFS）**

- **基本原理**：逐层扩展节点，从起点开始，先探索所有离起点最近的节点，再探索更远的节点。目的是系统地展开并检查图中的所有节点，以找寻结果。换句话说，它并不考虑结果的可能位置，彻底地搜索整张图，直到找到结果为止。Dijkstra[单源最短路径](https://baike.baidu.com/item/单源最短路径/6975204?fromModule=lemma_inlink)算法和Prim[最小生成树](https://baike.baidu.com/item/最小生成树?fromModule=lemma_inlink)算法都采用了和宽度优先搜索类似的思想。

- **方法流程**：
  
  1. 使用队列保存待探索的节点。
  2. 每次从队列中取出一个节点，扩展其所有子节点，将未访问过的子节点加入队列。
  3. 直到找到目标节点或队列为空。
  
- **应用场景**：适用于寻找最短路径的无权图。

- **优点**：找到最短路径（对于无权图）。

- **缺点**：需要大量内存，复杂度为O(b^d)，其中b为分支因子，d为深度。

- 示例伪代码：

	```
	int BFS(Node start, Node target) {
	    入队(初始状态);
	    visited[初始状态] = true;
	    while(!空队) {
	        for() { // 状态转换
	            Node node = 队首元素;
	 
	            对node的处理，生成新node状态;
	 
	            if (visited[node] == true)
	                continue;
	            if (node == target) {
	                输出答案;
	                return 0;
	            }
	            v[node] = true;
	            入队(node);
	        }
	    出队();
	    }
	    
	}
	```

	

#### 2. **一致代价搜索（Uniform Cost Search, UCS）**

- **基本原理**：扩展代价最小的节点，确保以最低代价到达目标节点。一致代价搜索总是扩展路径消耗最小的节点N。N点的路径消耗等于前一节点N-1的路径消耗加上N-1到N节点的路径消耗。
- **方法流程**：
  1. 使用优先队列保存待扩展的节点，按路径代价排序。
  2. 每次取出代价最小的节点扩展，更新路径代价。
  3. 找到目标节点时终止。
- **应用场景**：用于加权图寻找最低代价路径。
- **优点**：保证找到最低代价路径。
- **缺点**：若所有路径代价较相近，可能退化为BFS，耗时长。

#### 3. **深度优先搜索（Depth-First Search, DFS）**

- **基本原理**：沿着一条路径深入探索，直到不能继续为止，再回溯探索其他路径。深度优先搜索是图论中的经典算法，利用深度优先搜索算法可以产生目标图的相应拓扑排序表，利用拓扑排序表可以方便的解决很多相关的图论问题，如最大路径问题等等。一般用栈数据结构来辅助实现DFS算法。根据深度优先搜索的特点，采用递归函数实现比较简单。但也可以不采用递归.
- **方法流程**：
  1. 使用栈保存待探索的节点。
  2. 每次从栈顶取出一个节点，扩展其子节点并依次压入栈中。
  3. 直到找到目标节点或栈为空。
- **应用场景**：适用于解空间大且解较深的场景。(玩的galgame游戏，攻略了某一个线，退回最近那个节点攻略下一个)
- **优点**：内存消耗小，适合大规模问题。
- **缺点**：可能陷入死循环或长路径上，无法保证找到最短路径。

```
int dxy[4][2]={//模拟上下左右四个方向
	-1,0,//向上（x减一，y不变）
	1, 0,//向下
	0,-1,//向左
	0, 1//向右
	}
void dfs(int x0,int y0)
{
	if(x0,y0满足某种条件)//找到目标点
	{
		//执行操作如输出路径等
		return；
	}
	for(int i=0;i<4;i++)//遍历四个方向每一个分支，对每一个分支都进行深度搜索
	{
		int dx=dxy[i][0];//移动后的横坐标
		int dy=dxy[i][1];//移动后的纵坐标
		if(坐标越界||遇到障碍物||...)//不满足条件
			continue;
		//执行操作
		dfs(dx,dy)//深度遍历
		//遍历结束恢复操作
	}
}
```



#### 4. **深度受限搜索（Depth-Limited Search, DLS）**
- **基本原理**：与DFS类似，但限定搜索深度，避免陷入无穷循环。
- **方法流程**：设置一个最大深度，DFS只能深入到该深度，超出时回溯。
- **应用场景**：适用于有循环或需要限制搜索深度的场景。
- **优点**：控制递归深度，避免死循环。
- **缺点**：可能遗漏更深处的解，若深度设得不够大。

#### 5. **迭代加深搜索（Iterative Deepening Depth-First Search, IDDFS）**

reference from oi wiki

- **基本原理**：逐渐增加深度限制，重复执行DLS，直到找到解。

- **方法流程**：
  
  1. 设定初始深度限制，执行DLS。
  2. 若未找到解，增大深度限制并重复步骤1。
  
- **应用场景**：适用于大规模问题且解的深度未知。

- **优点**：结合了DFS的低内存需求和BFS的最优解保障。

- **缺点**：重复搜索导致效率降低，但实践中影响不大。

	```
	IDDFS(u,d)
	    if d>limit
	        return
	    else
	        for each edge (u,v)
	            IDDFS(v,d+1)
	return
	```

	

#### 6. **双向搜索（Bidirectional Search）**

reference from oi wiki

- **基本原理**：双向同时搜索的基本思路是从状态图上的起点和终点同时开始进行 [广搜](https://oi-wiki.org/search/bfs/) 或 [深搜](https://oi-wiki.org/search/dfs/)。

	如果发现搜索的两端相遇了，那么可以认为是获得了可行解。

- **方法流程**：
  
  1. 从起点和终点分别进行BFS。
  2. 当两边搜索的节点相遇时，路径找到。
  
- **应用场景**：适用于有明确目标的图搜索问题。

- **优点**：理论上可将搜索复杂度减半。

- **缺点**：需要同时维护两个搜索前沿，且在复杂图中难以实现。

### 有信息（启发式）搜索方法（Informed Search Methods）

#### 7. **贪婪最佳优先搜索（Greedy Best-First Search）**
- **基本原理**：优先扩展估计距离目标最近的节点，使用启发式函数h(n)。
- **方法流程**：
  1. 使用优先队列保存待扩展节点，按h(n)值排序。
  2. 每次扩展h(n)最小的节点，直到找到目标。
- **应用场景**：适用于路径代价无关或只关心最快找到解的场景。
- **优点**：较快找到目标，内存消耗小。
- **缺点**：不保证找到最优解，可能陷入局部最优。

#### 8. **A\*搜索（A* Search）**

- **基本原理**：结合代价和启发式信息，优先扩展f(n) = g(n) + h(n)最小的节点，其中g(n)是从起点到当前节点的代价，h(n)是启发式估计。
- **方法流程**：
  1. 使用优先队列按f(n)值排序节点。
  2. 每次扩展f(n)最小的节点，更新路径。
  3. 找到目标节点时停止。
- **应用场景**：适用于路径代价重要、启发式信息可靠的场景。
- **优点**：找到最优解，若启发式函数h(n)是可接受的（低于或等于实际代价）。
- **缺点**：内存和时间开销大，受启发式函数的影响较大。

#### 9. **递归最佳优先搜索（Recursive Best-First Search, RBFS）**

- **基本原理**：递归执行贪婪搜索，通过回溯控制递归深度。
- **方法流程**：类似A*，但采用递归方式，每次扩展时根据当前f值进行回溯调整。
	- 记录当前节点的祖先可得到的最佳可替换路径的f值。
	- 如果当前的f值超过了这个限制，则递归将转回到替换路径。
	- 向上回溯改变f值到它的孩子的最佳f 值
	- 重复扩展这个上个节点，因为仍有可能存在较优解。
		依旧上图上例子

- **应用场景**：适用于内存有限的场景。
- **优点**：内存需求低于A*，仍能找到最优解。
- **缺点**：搜索路径冗长时效率较低,时间复杂度取决于启发函数h的精度和最佳路劲变换的次数。

### 局部搜索算法（Local Search Algorithms）

#### 10. **爬山法（Hill Climbing）**

- **基本原理**：从当前状态向代价最小的邻居状态移动，期望找到全局最优解，其本质上是梯度下降法。

- **方法流程**：

  1. 每次从当前的节点开始，与周围的邻接点进行比较：
  2. 若当前节点是最大的，那么返回当前节点，作为最大值
  3. 若当前节点是最小的，就用最高的邻接点替换当前节点，从而实现向山峰的高处攀爬的目的

  	如此循环往复，直到达到最高点为止。

- **应用场景**：适用于解空间较大但全局信息不完全的问题。

- **优点**：简单易实现，内存需求低。

- **缺点**：

	- 局部最大，即某个节点会比周围任何一个邻居都高，但只是局部最优解，并非全局最优解。
	- 高地问题：搜索一旦到达高地，就无法确定搜索最佳方向，会产生随机走动，使得搜索效率降低
	- 山脊问题：搜索可能会在山脊的两面来回震荡，前进步伐很小


```
int getPos(double x) {//比较答案并获取新坐标点
    int pos;//新坐标点
    double res = -INF;
    for (int i = 1; i <= n; i++) {
        double newRes = getRes(x, node[i]);//获取新状态答案
        if (newRes > res) { //比较答案
            res = newRes; //更新结果
            pos = i; //记录新坐标点
        }
    }
    return pos;
}
void HC(double &x,double &y) {
    double T = 1;
    while (T > EPS) {
        int pos = getPos(x);//获取下一状态的坐标
        sta = sta + (node[pos] - x) * T;//转移x状态
        T *= 0.96;
    }
}
```



#### 11. **模拟退火法（Simulated Annealing）**

- **基本原理**：借鉴物理退火过程，其出发点是基于物理中固体物质的退火过程与一般的组合优化问题之间的相似性。算法允许在搜索过程中偶尔选择较差的状态，避免局部最优。

	模拟退火法是一种通用的优化算法，其物理退火过程由以下三部分组成:

	（1） 加温过程。其目的是增强粒子的热运动，使其偏离平衡位置。当温度足够高时，固体将熔为液体，从而消除系统原先存在的非均匀状态。

	（2） 等温过程。对于与周围环境交换热量而温度不变的封闭系统，系统状态的自发变化总是朝自由能减少的方向进行的，当自由能达到最小时，系统达到平衡状态。

	（3） 冷却过程。使粒子热运动减弱，系统能量下降，得到晶体结构。

	加温过程相当于对算法设定初值，等温过程对应算法的Metropolis抽样过程，冷却过程对应控制参数的下降。这里能量的变化就是目标函数，我们要得到的最优解就是能量最低态。其中Metropolis准则是SA算法收敛于全局最优解的关键所在，Metropolis准则以一定的概率接受恶化解，这样就使算法跳离局部最优的陷阱。

- **方法流程**：
  
  1. 从初始状态开始，每次根据温度参数选择下一个状态。
  2. 温度逐渐降低，减少选择较差状态的概率。
  3. 直到温度趋于零，结束搜索。
  
- **应用场景**：适用于解空间复杂且容易陷入局部最优的场景。

- **优点**：能够跳出局部最优，理论上能找到全局最优解。

- **缺点**：需要调节温度参数，收敛速度慢。

```
//目的：求系统的最小值
S(i):       系统在状态y时的评价函数值
i：　　　 　　系统当前状态
i + 1:　 　　系统的新状态
rate:       控制降温的速率
T0:         系统的初始温度（高温状态）
T_min:      温度的下限
 
while (T0 > T_min)
{
    dE = S(i + 1) - S(i);
   
    if dE < 0
    　　//接收从S(i)到S(i+1)的移动
    else if (exp(-dE / T) > random(0,1))
    　　//接收从S(i)到S(i+1)的移动
    else
    　　//不接收从S(i)到S(i+1)的移动
    T0 = r * T0;        　　　　　　　　//降温退火(0 < r < 1 ; r越大, 降温越慢; r越小, 降温越快)
    i++;
}

```



#### 12. **遗传算法（Genetic Algorithm, GA）**

- **基本原理**：模仿自然选择，通过选择、交叉、变异操作进化群体，期望找到最优解。
- **方法流程**：
  1. 初始化种群。
  2. 根据适应度函数选择个体进行繁殖。
  3. 执行交叉和变异操作生成新个体。
  4. 重复进化，直到达到终止条件。
- **应用场景**：适用于复杂的优化问题，尤其是解空间较大且无明显启发式信息的情况。
- **优点**：能处理大规模搜索空间，适应多种问题。
- **缺点**：需要大量计算资源，收敛速度受参数影响。

### 对抗搜索算法（Adversarial Search Algorithms）

#### 13. **极小极大算法（Minimax Algorithm）**

- **基本原理**：用于对抗性游戏，玩家轮流选择最大化自己得分或最小化对方得分，最终选择最大化最

小可能损失的策略。
- **方法流程**：
  1. 构建决策树；
  2. 将评估函数应用于叶子结点；
  3. 自底向上计算每个结点的minimax值；
  4. 从根结点选择minimax值最大的分支，作为行动策略。
- minimax计算流程如下：
	1. 如果节点是终止节点：应用估值函数求值；
	2. 如果节点是max节点：找到每个子节点的值，将其中最大的子节点值作为该节点的值；
	3. 如果节点时min节点：找到每个子节点的值，将其中最小的子节点值作为该节点的值。
- **应用场景**：适用于二人对抗性游戏，如国际象棋、井字棋等。
- **优点**：能找到最优解。
- **缺点**：搜索复杂度高，树的深度和分支因子大时难以实际应用。

#### 14. **α-β 搜索算法（Alpha-Beta Pruning）**

- **基本原理**：Alpha-Beta剪枝算法可加速极小化极大算法的搜索过程。在构建和搜索决策树时，每个节点除存储局面估值之外，还存储可能取值的上下界。下界即为Alpha值，上界即为Beta值。
- **方法流程**：
  1. 在极小极大算法的基础上，引入α和β作为上下限值。
  2. 当子树的评估超出α或β时，停止扩展该子树。
  3. 继续评估其他子树。
- **应用场景**：同样适用于二人对抗性游戏。
- **优点**：大大减少计算量，提升效率。
- **缺点**：仍有较高的时间复杂度，适用范围受限。





### 局部择优搜索与全局择优搜索的相同处与区别各是什么？

​	局部择优搜索和全局择优搜索都是一种求解最优解的方法，但区别在于搜索的范围不同。局部择优搜索只考虑当前状态下的可行解，通过不断地寻找局部最优解来逐步接近全局最优解；而全局择优搜索则是在整个搜索空间中寻找最优解，需要考虑更加广泛的可行解。因此，局部择优搜索更容易陷入局部最优解而无法达到全局最优解，而全局择优搜索更加耗时和计算资源。