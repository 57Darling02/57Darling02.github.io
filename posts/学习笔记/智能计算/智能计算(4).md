---
title: 智能计算(4)
date: 2025-03-19 15:04:20
tags: 学习笔记 智能计算
---
# 智能计算(4)
### 竞争学习神经网络学习笔记
竞争学习神经网络属于层次型网络，包含输入层和竞争层，是无导师学习方式的一种，能够对输入模式进行分类和聚类。
1. **竞争学习的概念与原理**
    - **基本概念**
        - **模式相关概念**：模式是事物的标准样式等，模式类是具有共同特征的模式集合。分类是在导师信号指导下将输入模式分配到模式类，无导师指导的分类即聚类 ，依据相似性将相似模式样本归为一类。
        - **相似性测量**
            - **欧式距离法**：两个模式向量欧式距离越小越相似，可设定最大欧式距离T作为聚类判据。公式为$\left\| X - X_{i}\right\| =\sqrt{(X - X_{i})^{T}(X - X_{i})}$。
            - **余弦法**：模式向量夹角越小，余弦越大越相似，设置最大夹角$\Psi_{T}$作为聚类判据，适用于向量长度相同或特征与方向相关的测量。公式为$cos \psi=\frac{X^{T} X_{i}}{\| X\| \left\| X_{i}\right\| }$。
            - **内积法**：内积值越大相似度越高，当模式方向相同且长度相等时取最大值。公式为$X^{T} X_{i}=\| X\| \left\| X_{i}\right\| cos \psi$。
        - **侧抑制与竞争**：人眼等存在侧抑制现象，神经细胞兴奋会抑制周围细胞，最强抑制作用下竞争获胜者“惟我独兴”，即胜者为王。
        - **向量归一化**：将向量变成方向不变长度为1的单位向量，便于比较向量夹角，公式为$\hat{X}=\frac{X}{\| X\| }=\left(\frac{x_{1}}{\sqrt{\sum_{j = 1}^{n} x_{j}^{2}}}, \cdots, \frac{x_{n}}{\sqrt{\sum_{j = 1}^{n} x_{j}^{2}}}\right)^{T}$。
    - **竞争学习原理**
        - **竞争学习规则（胜者为王算法）**
            - **向量归一化**：将当前输入模式向量X和竞争层各神经元权向量$W_{j}$归一化，得到$\hat{X}$和$\widehat{W}_{j}$。
            - **寻找获胜神经元**：通过计算欧式距离或夹角余弦，找出与$\hat{X}$最相似的权向量$\widehat{W_{j^{*}}}$作为获胜神经元，$\left\| \hat{X}-\hat{W}_{j^{*}}\right\| =min _{j \in\{1,2, \cdots, m\}}\left\{\left\| \hat{X}-\hat{W}_{j}\right\| \right\}$，也可转化为求最大点积$\hat{W}_{j^{*}}^{T} \hat{X}=max _{j \in\{1,2, \cdots, m\}}\left(\hat{W}_{j}^{T} \hat{X}\right)$。
            - **网络输出与权值调整**：获胜神经元输出为1，其余为0。获胜神经元权向量调整公式为$W_{j^{*}}(t + 1)=\hat{W}_{j^{*}}(t)+\mu(t)(\hat{X}-\hat{W}_{j^{*}})$，调整后需重新归一化，直到学习率$\mu(t)$衰减到0。
        - **竞争学习原理示例**：以将模式分为2类为例，通过随机初始化权向量，按算法调整权值，经过多次训练后，权向量逐渐接近模式类中心向量。
2. **自组织特征映射（SOM）神经网络**
    - **SOM网络的生物学基础**：人脑感觉通道神经元有序排列，外界特定时空信息使大脑皮层特定区域兴奋，类似信息在对应区域连续映像，这是SOM网络竞争机制的生物学基础。训练后，SOM网络竞争层神经元会形成有序排列，功能相近的神经元靠近。
    - **SOM网的拓扑结构与权值调整域**
        - **拓扑结构**：SOM网有输入层和输出层（竞争层），输出层神经元排列形式包括一维线阵、二维平面阵和三维栅格阵等。
        - **权值调整域**：SOM网学习算法（Kohonen算法）在胜者为王算法基础上改进，获胜神经元及其邻近神经元都调整权向量。调整方式可用墨西哥帽函数、大礼帽函数和厨师帽函数表示，常使用简化函数。以获胜神经元为中心设定优胜邻域，邻域半径随训练次数增加而收缩。
    - **自组织特征映射网的运行原理与学习算法**
        - **运行原理**：分为训练和工作阶段。训练阶段，输入样本使输出层有节点获胜，获胜节点及其优胜邻域内节点权向量向输入向量方向调整，最终输出层各节点对特定模式类敏感，形成反映样本模式类分布的有序特征图。
        - **学习算法（Kohonen算法）**
            - **初始化**：对输出层权向量赋小随机数并归一化，建立初始优胜邻域，设定学习率初始值。
            - **接受输入**：从训练集中随机选取并归一化输入模式。
            - **寻找获胜节点**：计算输入模式与权向量点积，找出点积最大的获胜节点；若输入未归一化，则计算欧式距离找最小距离节点。
            - **定义优胜邻域**：以获胜节点为中心确定权值调整域，邻域随训练时间收缩。
            - **调整权值**：对优胜邻域内节点按$w_{i j}(t + 1)=w_{i j}(t)+\eta(t, N)[x_{i}^{p}-w_{i j}(t)]$调整权值，$\eta(t, N)$与训练时间和拓扑距离有关，如$\eta(t, N)=\eta(t) e^{-N}$  ，$\eta(t)$是单调下降函数。
            - **结束检查**：当学习率衰减到零或达到预定训练次数时结束训练，否则返回接受输入步骤。
        - **功能分析**
            - **保序映射**：能将输入空间样本模式类有序映射在输出层，如将不同动物按属性特征映射到二维输出平面，属性相似的动物位置相近。
            - **数据压缩**：可将高维空间样本在保持拓扑结构不变的条件下投影到低维空间，如29维动物属性向量经SOM网压缩为二维平面数据。
            - **特征抽取**：从高维空间样本向低维空间映射，可发现数据内在规律，如字符排序中根据向量分量相同情况分类，SOM网输出结果与树形结构相似。
3. **自组织特征映射网络的设计与应用**
    - **SOM网的设计基础**
        - **输出层设计**：节点数设计要合适，过少无法区分全部模式类，过多可能分类过细或出现死节点。节点排列形式依实际应用选择，如旅行路径用二维平面、一般分类用一维线阵、机器人手臂控制用三维栅格。
        - **权值初始化问题**：权值一般初始化为较小随机数，可从训练集中随机抽取样本作为初始权值，或计算全体样本中心向量后迭加小随机数作为初始值。
        - **优胜邻域 $N_{j^{*}}(t)$ 的设计**：邻域不断缩小，形状有正方形、六边形或圆形等，大小用邻域半径表示，可按经验选择，如$r(t)=C_{1}\left(1-\frac{t}{t_{m}}\right)$或$r(t)=C_{1} e^{-B_{1} t / t_{m}}$  。
        - **学习率η(t)的设计**：训练开始时学习率可较大，快速下降捕捉输入向量大致结构，然后在较小值缓降至0，精细调整权值，如$\eta(t)=C_{2}\left(1-\frac{t}{t_{m}}\right)$或$\eta(t)=C_{2} e^{-B_{2} t / t_{m}}$  。
    - **应用与设计实例**：给定输入模式设计SOM网，如设置学习率、优胜邻域半径变化，观察训练过程中权向量变化，最终得到输入模式在输出平面的映射图。 